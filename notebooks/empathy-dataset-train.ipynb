{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.11","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":11653318,"sourceType":"datasetVersion","datasetId":7313126}],"dockerImageVersionId":31041,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"%load_ext autoreload\n%autoreload 2 ","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-18T16:14:28.479238Z","iopub.execute_input":"2025-05-18T16:14:28.479421Z","iopub.status.idle":"2025-05-18T16:14:28.501728Z","shell.execute_reply.started":"2025-05-18T16:14:28.479405Z","shell.execute_reply":"2025-05-18T16:14:28.501290Z"}},"outputs":[],"execution_count":1},{"cell_type":"code","source":"%rm -rf /kaggle/working/empathy_dataset_transfer\n%cd /kaggle/working\n!git clone https://bedanar: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@github.com/psytechlab/empathy_dataset_transfer.git","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-18T16:37:27.430553Z","iopub.execute_input":"2025-05-18T16:37:27.431474Z","iopub.status.idle":"2025-05-18T16:37:28.319067Z","shell.execute_reply.started":"2025-05-18T16:37:27.431441Z","shell.execute_reply":"2025-05-18T16:37:28.318413Z"}},"outputs":[{"name":"stdout","text":"/kaggle/working\nCloning into 'empathy_dataset_transfer'...\n","output_type":"stream"},{"name":"stderr","text":"huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\nhuggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n","output_type":"stream"},{"name":"stdout","text":"remote: Enumerating objects: 233, done.\u001b[K\nremote: Counting objects: 100% (233/233), done.\u001b[K\nremote: Compressing objects: 100% (140/140), done.\u001b[K\nremote: Total 233 (delta 93), reused 191 (delta 58), pack-reused 0 (from 0)\u001b[K\nReceiving objects: 100% (233/233), 172.22 KiB | 9.06 MiB/s, done.\nResolving deltas: 100% (93/93), done.\n","output_type":"stream"}],"execution_count":56},{"cell_type":"code","source":"%cd /kaggle/working/empathy_dataset_transfer\n!git checkout empathy-models\n%cd /","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-18T16:37:29.613075Z","iopub.execute_input":"2025-05-18T16:37:29.613679Z","iopub.status.idle":"2025-05-18T16:37:29.806681Z","shell.execute_reply.started":"2025-05-18T16:37:29.613651Z","shell.execute_reply":"2025-05-18T16:37:29.805806Z"}},"outputs":[{"name":"stdout","text":"/kaggle/working/empathy_dataset_transfer\nBranch 'empathy-models' set up to track remote branch 'empathy-models' from 'origin'.\nSwitched to a new branch 'empathy-models'\n/\n","output_type":"stream"},{"name":"stderr","text":"huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n","output_type":"stream"}],"execution_count":57},{"cell_type":"code","source":"import sys\nsys.path.append(\"/kaggle/working/empathy_dataset_transfer\") \nsys.path.append(\"/kaggle/working/empathy_dataset_transfer/src\") \nsys.path.append(\"/kaggle/working/empathy_dataset_transfer/src/contrib\") \nsys.path.append(\"/kaggle/working/empathy_dataset_transfer/src/contrib/empathy_models\") ","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-18T16:37:30.275604Z","iopub.execute_input":"2025-05-18T16:37:30.275870Z","iopub.status.idle":"2025-05-18T16:37:30.669022Z","shell.execute_reply.started":"2025-05-18T16:37:30.275846Z","shell.execute_reply":"2025-05-18T16:37:30.668359Z"}},"outputs":[],"execution_count":58},{"cell_type":"code","source":"import codecs\nimport numpy as np\nimport pandas as pd\nimport re\nimport math\nimport numpy as np\nimport random\nimport time\nimport datetime\nimport argparse\nfrom tqdm import tqdm\n\nimport torch\nfrom torch.utils.data import DataLoader, RandomSampler, SequentialSampler\nfrom torch.utils.data import TensorDataset, random_split\n\nfrom transformers import RobertaTokenizer\nfrom transformers import RobertaConfig\nfrom torch.optim import AdamW\nfrom transformers import get_linear_schedule_with_warmup\nfrom sklearn.model_selection import train_test_split\nfrom src.contrib.empathy_models.models.models import BiEncoderAttentionWithRationaleClassification\nfrom src.contrib.empathy_models.evaluation_utils import *","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-05-18T16:37:30.950686Z","iopub.execute_input":"2025-05-18T16:37:30.951207Z","iopub.status.idle":"2025-05-18T16:37:30.993269Z","shell.execute_reply.started":"2025-05-18T16:37:30.951188Z","shell.execute_reply":"2025-05-18T16:37:30.992648Z"}},"outputs":[],"execution_count":59},{"cell_type":"code","source":"lr = 2e-5\nlambda_EI = 1\nlambda_RE = 0.5\ndropout = 0.1\nmax_len = 128\nbatch_size = 4\nepochs = 5\nseed_val = 12\nmodel_name = 'DeepPavlov/rubert-base-cased'\n\nif torch.cuda.is_available():\n\tdevice = torch.device(\"cuda\")\nelse:\n\tprint('No GPU available, using the CPU instead.')\n\tdevice = torch.device(\"cpu\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-18T16:37:32.925411Z","iopub.execute_input":"2025-05-18T16:37:32.926131Z","iopub.status.idle":"2025-05-18T16:37:32.967892Z","shell.execute_reply.started":"2025-05-18T16:37:32.926095Z","shell.execute_reply":"2025-05-18T16:37:32.967317Z"}},"outputs":[],"execution_count":60},{"cell_type":"code","source":"random.seed(seed_val)\nnp.random.seed(seed_val)\ntorch.manual_seed(seed_val)\ntorch.cuda.manual_seed_all(seed_val)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-18T16:37:34.520509Z","iopub.execute_input":"2025-05-18T16:37:34.520759Z","iopub.status.idle":"2025-05-18T16:37:34.563364Z","shell.execute_reply.started":"2025-05-18T16:37:34.520743Z","shell.execute_reply":"2025-05-18T16:37:34.562663Z"}},"outputs":[],"execution_count":61},{"cell_type":"code","source":"%ls kaggle/input","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-18T16:37:34.880194Z","iopub.execute_input":"2025-05-18T16:37:34.880436Z","iopub.status.idle":"2025-05-18T16:37:35.064209Z","shell.execute_reply.started":"2025-05-18T16:37:34.880420Z","shell.execute_reply":"2025-05-18T16:37:35.063415Z"}},"outputs":[{"name":"stdout","text":"emotional-reactions-reddit.csv  interpretations-reddit.csv\nexplorations-reddit.csv\n","output_type":"stream"},{"name":"stderr","text":"huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n","output_type":"stream"}],"execution_count":62},{"cell_type":"code","source":"!python /kaggle/working/empathy_dataset_transfer/src/contrib/empathy_models/process_data.py --input_path=/kaggle/input/emotional-reactions-reddit.csv --output_path=/kaggle/working/emotional-reactions-reddit.csv\n!python /kaggle/working/empathy_dataset_transfer/src/contrib/empathy_models/process_data.py --input_path=/kaggle/input/explorations-reddit.csv --output_path=/kaggle/working/explorations-reddit.csv\n!python /kaggle/working/empathy_dataset_transfer/src/contrib/empathy_models/process_data.py --input_path=/kaggle/input/interpretations-reddit.csv --output_path=/kaggle/working/interpretations-reddit.csv","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-18T16:37:35.776860Z","iopub.execute_input":"2025-05-18T16:37:35.777591Z","iopub.status.idle":"2025-05-18T16:38:11.661010Z","shell.execute_reply.started":"2025-05-18T16:37:35.777565Z","shell.execute_reply":"2025-05-18T16:38:11.660315Z"}},"outputs":[{"name":"stderr","text":"huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\nhuggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\nhuggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n","output_type":"stream"}],"execution_count":63},{"cell_type":"code","source":"# df_all = pd.read_csv('/kaggle/working/emotional-reactions-reddit.csv', delimiter=',')\n# df_all = pd.read_csv('/kaggle/working/explorations-reddit.csv', delimiter=',')\ndf_all = pd.read_csv('/kaggle/working/interpretations-reddit.csv', delimiter=',')\n\ndf, validation = train_test_split(df_all, train_size=0.7, random_state=42)\ndf_val, df_test = train_test_split(validation, test_size=0.5, random_state=42)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-18T16:38:27.050372Z","iopub.execute_input":"2025-05-18T16:38:27.050669Z","iopub.status.idle":"2025-05-18T16:38:27.190038Z","shell.execute_reply.started":"2025-05-18T16:38:27.050643Z","shell.execute_reply":"2025-05-18T16:38:27.189533Z"}},"outputs":[],"execution_count":64},{"cell_type":"code","source":"# train_path = \"/kaggle/working/sample_input_ER_out.csv\"\n# dev_path = \"/kaggle/working/sample_input_ER_out.csv\"\n# test_path = \"/kaggle/working/sample_input_ER_out.csv\"\nsave_model_path = '/kaggle/working/interpretations_model_output'","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-18T16:38:27.831759Z","iopub.execute_input":"2025-05-18T16:38:27.831966Z","iopub.status.idle":"2025-05-18T16:38:27.872615Z","shell.execute_reply.started":"2025-05-18T16:38:27.831951Z","shell.execute_reply":"2025-05-18T16:38:27.871963Z"}},"outputs":[],"execution_count":65},{"cell_type":"code","source":"# df = pd.read_csv(train_path, delimiter=',')\ndf['rationale_labels'] = df['rationale_labels'].apply(lambda s: torch.tensor(np.asarray([int(i) for i in s.split(',')]), dtype=torch.long))\n\n# df_test = pd.read_csv(test_path, delimiter=',')\ndf_test['rationale_labels'] = df_test['rationale_labels'].apply(lambda s: torch.tensor(np.asarray([int(i) for i in s.split(',')]), dtype=torch.long))\n\n# df_val = pd.read_csv(dev_path, delimiter=',')\ndf_val['rationale_labels'] = df_val['rationale_labels'].apply(lambda s: torch.tensor(np.asarray([int(i) for i in s.split(',')]), dtype=torch.long))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-18T16:38:28.475895Z","iopub.execute_input":"2025-05-18T16:38:28.476367Z","iopub.status.idle":"2025-05-18T16:38:28.618739Z","shell.execute_reply.started":"2025-05-18T16:38:28.476350Z","shell.execute_reply":"2025-05-18T16:38:28.618268Z"}},"outputs":[],"execution_count":66},{"cell_type":"code","source":"# set([len(i) for i in tokenizer_RP['input_ids']])","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-18T16:38:54.275256Z","iopub.execute_input":"2025-05-18T16:38:54.275521Z","iopub.status.idle":"2025-05-18T16:38:54.317050Z","shell.execute_reply.started":"2025-05-18T16:38:54.275502Z","shell.execute_reply":"2025-05-18T16:38:54.316354Z"}},"outputs":[],"execution_count":71},{"cell_type":"code","source":"# tokenizer = RobertaTokenizer.from_pretrained(model_name, do_lower_case=True)\nfrom transformers import AutoTokenizer\ntokenizer = AutoTokenizer.from_pretrained(model_name)\n\ntokenizer_RP = tokenizer.batch_encode_plus(df.response_post.tolist(), add_special_tokens=True, max_length=max_len, truncation=True, padding='max_length', return_attention_mask=True)\ninput_ids_RP = torch.tensor(tokenizer_RP['input_ids'])\nattention_masks_RP = torch.tensor(tokenizer_RP['attention_mask'])\n\ntokenizer_SP = tokenizer.batch_encode_plus(df.seeker_post.tolist(), add_special_tokens=True, max_length=max_len, truncation=True, padding='max_length', return_attention_mask=True)\ninput_ids_SP = torch.tensor(tokenizer_SP['input_ids'])\nattention_masks_SP = torch.tensor(tokenizer_SP['attention_mask'])","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-18T16:40:07.737611Z","iopub.execute_input":"2025-05-18T16:40:07.738210Z","iopub.status.idle":"2025-05-18T16:40:08.686368Z","shell.execute_reply.started":"2025-05-18T16:40:07.738185Z","shell.execute_reply":"2025-05-18T16:40:08.685561Z"}},"outputs":[],"execution_count":73},{"cell_type":"code","source":"labels = df.level.values.astype(int)\nlabels = torch.tensor(labels)\nrationales = df.rationale_labels.values.tolist()\nrationales = torch.stack(rationales, dim=0)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-18T16:40:14.674865Z","iopub.execute_input":"2025-05-18T16:40:14.675482Z","iopub.status.idle":"2025-05-18T16:40:14.733085Z","shell.execute_reply.started":"2025-05-18T16:40:14.675460Z","shell.execute_reply":"2025-05-18T16:40:14.732159Z"}},"outputs":[],"execution_count":74},{"cell_type":"code","source":"val_tokenizer_RP = tokenizer.batch_encode_plus(df_val.response_post.tolist(), add_special_tokens=True, truncation=True, max_length=max_len, padding='max_length', return_attention_mask=True)\nval_input_ids_RP = torch.tensor(val_tokenizer_RP['input_ids'])\nval_attention_masks_RP = torch.tensor(val_tokenizer_RP['attention_mask'])\n\nval_tokenizer_SP = tokenizer.batch_encode_plus(df_val.seeker_post.tolist(), add_special_tokens=True, truncation=True, max_length=max_len, padding='max_length', return_attention_mask=True)\nval_input_ids_SP = torch.tensor(val_tokenizer_SP['input_ids'])\nval_attention_masks_SP = torch.tensor(val_tokenizer_SP['attention_mask'])\n\nval_labels = torch.tensor(df_val.level.values.astype(int))\nval_rationales = df_val.rationale_labels.values.tolist()\nval_rationales = torch.stack(val_rationales, dim=0)\nval_rationales_trimmed = torch.tensor(df_val.rationale_labels_trimmed.values.astype(int))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-18T16:40:38.340380Z","iopub.execute_input":"2025-05-18T16:40:38.341071Z","iopub.status.idle":"2025-05-18T16:40:38.498175Z","shell.execute_reply.started":"2025-05-18T16:40:38.341049Z","shell.execute_reply":"2025-05-18T16:40:38.497639Z"}},"outputs":[],"execution_count":75},{"cell_type":"code","source":"test_tokenizer_RP = tokenizer.batch_encode_plus(df_test.response_post.tolist(), add_special_tokens=True, max_length=max_len, padding='max_length', truncation=True, return_attention_mask=True)\ntest_input_ids_RP = torch.tensor(test_tokenizer_RP['input_ids'])\ntest_attention_masks_RP = torch.tensor(test_tokenizer_RP['attention_mask'])\n\ntest_tokenizer_SP = tokenizer.batch_encode_plus(df_test.seeker_post.tolist(), add_special_tokens=True, max_length=max_len, padding='max_length', truncation=True, return_attention_mask=True)\ntest_input_ids_SP = torch.tensor(test_tokenizer_SP['input_ids'])\ntest_attention_masks_SP = torch.tensor(test_tokenizer_SP['attention_mask'])\n\ntest_labels = torch.tensor(df_test.level.values.astype(int))\ntest_rationales = df_test.rationale_labels.values.tolist()\ntest_rationales = torch.stack(test_rationales, dim=0)\ntest_rationales_trimmed = torch.tensor(df_test.rationale_labels_trimmed.values.astype(int))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-18T16:41:02.464199Z","iopub.execute_input":"2025-05-18T16:41:02.464466Z","iopub.status.idle":"2025-05-18T16:41:02.616849Z","shell.execute_reply.started":"2025-05-18T16:41:02.464447Z","shell.execute_reply":"2025-05-18T16:41:02.616147Z"}},"outputs":[],"execution_count":76},{"cell_type":"code","source":"model = BiEncoderAttentionWithRationaleClassification(model_name=model_name, hidden_dropout_prob=dropout)\nmodel = model.to(device)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-18T16:41:06.723667Z","iopub.execute_input":"2025-05-18T16:41:06.724218Z","iopub.status.idle":"2025-05-18T16:41:29.587693Z","shell.execute_reply.started":"2025-05-18T16:41:06.724195Z","shell.execute_reply":"2025-05-18T16:41:29.587145Z"}},"outputs":[{"name":"stderr","text":"2025-05-18 16:41:12.607279: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\nWARNING: All log messages before absl::InitializeLog() is called are written to STDERR\nE0000 00:00:1747586472.798965      35 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\nE0000 00:00:1747586472.853894      35 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"pytorch_model.bin:   0%|          | 0.00/714M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"616cbc55faea4119acdbde0035796ad7"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model.safetensors:   0%|          | 0.00/714M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"1ecf26c7aa4c4e89917c29deb98b3ed1"}},"metadata":{}},{"name":"stderr","text":"Some weights of the model checkpoint at DeepPavlov/rubert-base-cased were not used when initializing BertModel: ['cls.predictions.bias', 'cls.predictions.decoder.bias', 'cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.dense.weight', 'cls.seq_relationship.bias', 'cls.seq_relationship.weight']\n- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\nSome weights of the model checkpoint at DeepPavlov/rubert-base-cased were not used when initializing BertModel: ['cls.predictions.bias', 'cls.predictions.decoder.bias', 'cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.dense.weight', 'cls.seq_relationship.bias', 'cls.seq_relationship.weight']\n- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","output_type":"stream"}],"execution_count":77},{"cell_type":"code","source":"params = list(model.named_parameters())\nfor p in model.seeker_encoder.parameters():\n\tp.requires_grad = False","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-18T16:41:29.588994Z","iopub.execute_input":"2025-05-18T16:41:29.589517Z","iopub.status.idle":"2025-05-18T16:41:29.661390Z","shell.execute_reply.started":"2025-05-18T16:41:29.589498Z","shell.execute_reply":"2025-05-18T16:41:29.660788Z"}},"outputs":[],"execution_count":78},{"cell_type":"code","source":"optimizer = AdamW(model.parameters(), lr = lr, eps = 1e-8)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-18T16:41:29.662425Z","iopub.execute_input":"2025-05-18T16:41:29.662678Z","iopub.status.idle":"2025-05-18T16:41:29.732711Z","shell.execute_reply.started":"2025-05-18T16:41:29.662654Z","shell.execute_reply":"2025-05-18T16:41:29.732129Z"}},"outputs":[],"execution_count":79},{"cell_type":"code","source":"train_dataset = TensorDataset(input_ids_SP, attention_masks_SP, input_ids_RP, attention_masks_RP, labels, rationales)\ntrain_size = int(len(train_dataset))\ntrain_dataloader = DataLoader(train_dataset, sampler = RandomSampler(train_dataset), batch_size = batch_size)\n\nval_dataset = TensorDataset(val_input_ids_SP, val_attention_masks_SP, val_input_ids_RP, val_attention_masks_RP, val_labels, val_rationales, val_rationales_trimmed)\nvalidation_dataloader = DataLoader(val_dataset, sampler = SequentialSampler(val_dataset), batch_size = batch_size)\n\ntest_dataset = TensorDataset(test_input_ids_SP, test_attention_masks_SP, test_input_ids_RP, test_attention_masks_RP, test_labels, test_rationales, test_rationales_trimmed)\ntest_dataloader = DataLoader(test_dataset, sampler = SequentialSampler(test_dataset), batch_size = batch_size)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-18T16:41:34.291979Z","iopub.execute_input":"2025-05-18T16:41:34.292522Z","iopub.status.idle":"2025-05-18T16:41:34.371509Z","shell.execute_reply.started":"2025-05-18T16:41:34.292499Z","shell.execute_reply":"2025-05-18T16:41:34.370778Z"}},"outputs":[],"execution_count":80},{"cell_type":"code","source":"total_steps = len(train_dataloader) * epochs\nnum_batch = len(train_dataloader)\n\nscheduler = get_linear_schedule_with_warmup(optimizer, num_warmup_steps = 0, num_training_steps = total_steps)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-18T16:41:36.104595Z","iopub.execute_input":"2025-05-18T16:41:36.105346Z","iopub.status.idle":"2025-05-18T16:41:36.382692Z","shell.execute_reply.started":"2025-05-18T16:41:36.105313Z","shell.execute_reply":"2025-05-18T16:41:36.381930Z"}},"outputs":[],"execution_count":81},{"cell_type":"code","source":"for epoch_i in range(0, epochs):\n    total_train_loss = 0\n    total_train_empathy_loss = 0\n    total_train_rationale_loss = 0\n    \n    pbar = tqdm(total=num_batch, desc=f\"training\")\n    \n    model.train()\n    for step, batch in enumerate(train_dataloader):\n        b_input_ids_SP = batch[0].to(device)\n        b_input_mask_SP = batch[1].to(device)\n        b_input_ids_RP = batch[2].to(device)\n        b_input_mask_RP = batch[3].to(device)\n        b_labels = batch[4].to(device)\n        b_rationales = batch[5].to(device)\n        \n        model.zero_grad()        \n        \n        loss, loss_empathy, loss_rationale, logits_empathy, logits_rationale = model(input_ids_SP = b_input_ids_SP,\n                                                                input_ids_RP = b_input_ids_RP, \n                                                                attention_mask_SP=b_input_mask_SP,\n                                                                attention_mask_RP=b_input_mask_RP, \n                                                                empathy_labels=b_labels,\n                                                                rationale_labels=b_rationales,\n                                                                lambda_EI=lambda_EI,\n                                                                lambda_RE=lambda_RE)\n        \n        \n        total_train_loss += loss.item()\n        total_train_empathy_loss += loss_empathy.item()\n        total_train_rationale_loss += loss_rationale.item()\n        \n        loss.backward()\n        \n        torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n        \n        optimizer.step()\n        scheduler.step()\n        \n        pbar.set_postfix_str(\n            f\"total loss: {float(total_train_loss/(step+1)):.4f} epoch: {epoch_i}\")\n        pbar.update(1)\n\n    avg_train_loss = total_train_loss / len(train_dataloader)\n    avg_train_empathy_loss = total_train_empathy_loss / len(train_dataloader)\n    avg_train_rationale_loss = total_train_rationale_loss / len(train_dataloader)\n    \n    pbar.close()\n    model.eval()\n    \n    total_eval_accuracy_empathy = 0\n    total_eval_accuracy_rationale = 0\n    \n    total_pos_f1_empathy = 0.0\n    total_micro_f1_empathy = 0.0\n    total_macro_f1_empathy = 0.0\n    \n    total_pos_f1_rationale = 0.0\n    total_micro_f1_rationale = 0.0\n    total_macro_f1_rationale = 0.0\n    \n    total_iou_rationale = 0.0\n    \n    total_eval_loss = 0\n\n    for batch in validation_dataloader:   \n        b_input_ids_SP = batch[0].to(device)\n        b_input_mask_SP = batch[1].to(device)\n        b_input_ids_RP = batch[2].to(device)\n        b_input_mask_RP = batch[3].to(device)\n        b_labels = batch[4].to(device)\n        b_rationales = batch[5].to(device)\t\n        b_rationales_trimmed = batch[6].to(device)\t\n        \n        with torch.no_grad():\n            loss, loss_empathy, loss_rationale, logits_empathy, logits_rationale = model(input_ids_SP = b_input_ids_SP,\n                                                                input_ids_RP = b_input_ids_RP, \n                                                                attention_mask_SP=b_input_mask_SP,\n                                                                attention_mask_RP=b_input_mask_RP, \n                                                                empathy_labels=b_labels,\n                                                                rationale_labels=b_rationales,\n                                                                lambda_EI=lambda_EI,\n                                                                lambda_RE=lambda_RE)\n        \n        total_eval_loss += loss.item()\n        \n        logits_empathy = logits_empathy.detach().cpu().numpy()\n        logits_rationale = logits_rationale.detach().cpu().numpy()\n        \n        label_empathy_ids = b_labels.to('cpu').numpy()\n        label_rationale_ids = b_rationales.to('cpu').numpy()\n        rationale_lens = b_rationales_trimmed.to('cpu').numpy()\n        \n        total_eval_accuracy_empathy += flat_accuracy(logits_empathy, label_empathy_ids, axis_=1)\n        total_eval_accuracy_rationale += flat_accuracy_rationale(logits_rationale, label_rationale_ids, label_empathy_ids, rationale_lens, axis_=2)\n        \n        pos_f1_empathy, micro_f1_empathy, macro_f1_empathy = compute_f1(logits_empathy, label_empathy_ids, axis_=1)\n        macro_f1_rationale = compute_f1_rationale(logits_rationale, label_rationale_ids, label_empathy_ids, rationale_lens, axis_=2)\n        \n        iou_f1_rationale = iou_f1(logits_rationale, label_rationale_ids, label_empathy_ids, rationale_lens, axis_=2)\n        \n        total_pos_f1_empathy += pos_f1_empathy\n        total_micro_f1_empathy += micro_f1_empathy\n        total_macro_f1_empathy += macro_f1_empathy\n        \n        total_macro_f1_rationale += macro_f1_rationale\n        total_iou_rationale += iou_f1_rationale\n\n    avg_val_accuracy_empathy = total_eval_accuracy_empathy / len(validation_dataloader)\n    avg_val_accuracy_rationale = total_eval_accuracy_rationale / len(validation_dataloader)\n    \n    avg_val_pos_f1_empathy = total_pos_f1_empathy / len(validation_dataloader)\n    avg_val_micro_f1_empathy = total_micro_f1_empathy / len(validation_dataloader)\n    avg_val_macro_f1_empathy = total_macro_f1_empathy / len(validation_dataloader)\n    \n    avg_val_macro_f1_rationale = total_macro_f1_rationale / len(validation_dataloader)\n    avg_val_iou_rationale = total_iou_rationale / len(validation_dataloader)\n    \n    print(\"  Accuracy-Empathy: {0:.4f}\".format(avg_val_accuracy_empathy))\n    print(\"  macro_f1_empathy: {0:.4f}\".format(avg_val_macro_f1_empathy))\n    print(\"  Accuracy-Rationale: {0:.4f}\".format(avg_val_accuracy_rationale))\n    \n    print(\"  IOU-F1-Rationale: {0:.4f}\".format(avg_val_iou_rationale))\n    print(\"  macro_f1_rationale: {0:.4f}\".format(avg_val_macro_f1_rationale))\n    \n    avg_val_loss = total_eval_loss / len(validation_dataloader)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-18T16:41:36.654979Z","iopub.execute_input":"2025-05-18T16:41:36.655228Z","iopub.status.idle":"2025-05-18T16:51:19.019806Z","shell.execute_reply.started":"2025-05-18T16:41:36.655210Z","shell.execute_reply":"2025-05-18T16:51:19.019119Z"}},"outputs":[{"name":"stderr","text":"training: 100%|██████████| 540/540 [01:39<00:00,  5.45it/s, total loss: 0.9001 epoch: 0]\n","output_type":"stream"},{"name":"stdout","text":"  Accuracy-Empathy: 0.8182\n  macro_f1_empathy: 0.7415\n  Accuracy-Rationale: 0.6187\n  IOU-F1-Rationale: 0.5030\n  macro_f1_rationale: 0.5757\n","output_type":"stream"},{"name":"stderr","text":"training: 100%|██████████| 540/540 [01:49<00:00,  4.91it/s, total loss: 0.7217 epoch: 1]\n","output_type":"stream"},{"name":"stdout","text":"  Accuracy-Empathy: 0.8125\n  macro_f1_empathy: 0.7377\n  Accuracy-Rationale: 0.6107\n  IOU-F1-Rationale: 0.5130\n  macro_f1_rationale: 0.5845\n","output_type":"stream"},{"name":"stderr","text":"training: 100%|██████████| 540/540 [01:49<00:00,  4.94it/s, total loss: 0.6034 epoch: 2]\n","output_type":"stream"},{"name":"stdout","text":"  Accuracy-Empathy: 0.8103\n  macro_f1_empathy: 0.7245\n  Accuracy-Rationale: 0.5842\n  IOU-F1-Rationale: 0.5906\n  macro_f1_rationale: 0.6175\n","output_type":"stream"},{"name":"stderr","text":"training: 100%|██████████| 540/540 [01:49<00:00,  4.94it/s, total loss: 0.4457 epoch: 3]\n","output_type":"stream"},{"name":"stdout","text":"  Accuracy-Empathy: 0.8103\n  macro_f1_empathy: 0.7320\n  Accuracy-Rationale: 0.5791\n  IOU-F1-Rationale: 0.5881\n  macro_f1_rationale: 0.6148\n","output_type":"stream"},{"name":"stderr","text":"training: 100%|██████████| 540/540 [01:49<00:00,  4.94it/s, total loss: 0.3513 epoch: 4]\n","output_type":"stream"},{"name":"stdout","text":"  Accuracy-Empathy: 0.8168\n  macro_f1_empathy: 0.7379\n  Accuracy-Rationale: 0.5984\n  IOU-F1-Rationale: 0.5890\n  macro_f1_rationale: 0.6089\n","output_type":"stream"}],"execution_count":82},{"cell_type":"code","source":"model.eval()\n\ntotal_eval_accuracy_empathy = 0\ntotal_eval_accuracy_rationale = 0\n\ntotal_pos_f1_empathy = 0.0\ntotal_micro_f1_empathy = 0.0\ntotal_macro_f1_empathy = 0.0\n\ntotal_pos_f1_rationale = 0.0\ntotal_micro_f1_rationale = 0.0\ntotal_macro_f1_rationale = 0.0\ntotal_iou_rationale = 0.0\n\ntotal_eval_loss = 0\n\nfor batch in test_dataloader:\n    \n    b_input_ids_SP = batch[0].to(device)\n    b_input_mask_SP = batch[1].to(device)\n    b_input_ids_RP = batch[2].to(device)\n    b_input_mask_RP = batch[3].to(device)\n    b_labels = batch[4].to(device)\n    b_rationales = batch[5].to(device)\n    b_rationales_trimmed = batch[6].to(device)\n\n    with torch.no_grad():\n        loss, loss_empathy, loss_rationale, logits_empathy, logits_rationale = model(input_ids_SP = b_input_ids_SP,\n                                                            input_ids_RP = b_input_ids_RP, \n                                                            attention_mask_SP=b_input_mask_SP,\n                                                            attention_mask_RP=b_input_mask_RP, \n                                                            empathy_labels=b_labels,\n                                                            rationale_labels=b_rationales,\n                                                            lambda_EI=lambda_EI,\n                                                            lambda_RE=lambda_RE)\n\n    total_eval_loss += loss.item()\n\n    logits_empathy = logits_empathy.detach().cpu().numpy()\n    logits_rationale = logits_rationale.detach().cpu().numpy()\n    \n    label_empathy_ids = b_labels.to('cpu').numpy()\n    label_rationale_ids = b_rationales.to('cpu').numpy()\n    rationale_lens = b_rationales_trimmed.to('cpu').numpy()\n\n    total_eval_accuracy_empathy += flat_accuracy(logits_empathy, label_empathy_ids, axis_=1)\n    total_eval_accuracy_rationale += flat_accuracy_rationale(logits_rationale, label_rationale_ids,  label_empathy_ids, rationale_lens, axis_=2)\n    \n    pos_f1_empathy, micro_f1_empathy, macro_f1_empathy = compute_f1(logits_empathy, label_empathy_ids, axis_=1)\n    macro_f1_rationale = compute_f1_rationale(logits_rationale, label_rationale_ids, label_empathy_ids, rationale_lens, axis_=2)\n\n    iou_f1_rationale = iou_f1(logits_rationale, label_rationale_ids, label_empathy_ids, rationale_lens, axis_=2)\n\n    total_pos_f1_empathy += pos_f1_empathy\n    total_micro_f1_empathy += micro_f1_empathy\n    total_macro_f1_empathy += macro_f1_empathy\n\n    total_macro_f1_rationale += macro_f1_rationale\n    total_iou_rationale += iou_f1_rationale\n\navg_test_accuracy_empathy = total_eval_accuracy_empathy / len(test_dataloader)\navg_test_accuracy_rationale = total_eval_accuracy_rationale / len(test_dataloader)\n\navg_test_pos_f1_empathy = total_pos_f1_empathy / len(test_dataloader)\navg_test_micro_f1_empathy = total_micro_f1_empathy / len(test_dataloader)\navg_test_macro_f1_empathy = total_macro_f1_empathy / len(test_dataloader)\n\navg_test_macro_f1_rationale = total_macro_f1_rationale / len(test_dataloader)\navg_test_iou_rationale = total_iou_rationale / len(test_dataloader)\n\nprint(\"  Accuracy-Empathy: {0:.4f}\".format(avg_test_accuracy_empathy))\nprint(\"  macro_f1_empathy: {0:.4f}\".format(avg_test_macro_f1_empathy))\nprint(\"  Accuracy-Rationale: {0:.4f}\".format(avg_test_accuracy_rationale))\n\nprint(\"  IOU-F1-Rationale: {0:.4f}\".format(avg_test_iou_rationale))\nprint(\"  macro_f1_rationale: {0:.4f}\".format(avg_test_macro_f1_rationale))\n\navg_test_loss = total_eval_loss / len(test_dataloader)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-18T16:51:19.021075Z","iopub.execute_input":"2025-05-18T16:51:19.021402Z","iopub.status.idle":"2025-05-18T16:51:28.093391Z","shell.execute_reply.started":"2025-05-18T16:51:19.021384Z","shell.execute_reply":"2025-05-18T16:51:28.092644Z"}},"outputs":[{"name":"stdout","text":"  Accuracy-Empathy: 0.8362\n  macro_f1_empathy: 0.7841\n  Accuracy-Rationale: 0.6084\n  IOU-F1-Rationale: 0.6199\n  macro_f1_rationale: 0.6180\n","output_type":"stream"}],"execution_count":83},{"cell_type":"code","source":"torch.save(model.state_dict(), save_model_path)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-18T16:51:37.508063Z","iopub.execute_input":"2025-05-18T16:51:37.508355Z","iopub.status.idle":"2025-05-18T16:51:39.894126Z","shell.execute_reply.started":"2025-05-18T16:51:37.508335Z","shell.execute_reply":"2025-05-18T16:51:39.893347Z"}},"outputs":[],"execution_count":84},{"cell_type":"markdown","source":"# inference","metadata":{}},{"cell_type":"code","source":"from src.models","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-03T11:28:42.344520Z","iopub.status.idle":"2025-05-03T11:28:42.344762Z","shell.execute_reply.started":"2025-05-03T11:28:42.344659Z","shell.execute_reply":"2025-05-03T11:28:42.344668Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"input_path = '/kaggle/working/Empathy-Mental-Health/dataset/sample_test_input.csv'\noutput_path = '/kaggle/working/sample_test_input_out.csv'\nER_model_path = \"/kaggle/working/model_output\"\nIP_model_path = \"/kaggle/working/interpretations_model_output\"\nEX_model_path = \"/kaggle/working/explorations_model_output\"","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-03T11:28:42.345927Z","iopub.status.idle":"2025-05-03T11:28:42.346131Z","shell.execute_reply.started":"2025-05-03T11:28:42.346033Z","shell.execute_reply":"2025-05-03T11:28:42.346042Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# input_df = pd.read_csv(input_path, header=0)\ninput_df = df_test","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-03T11:28:42.347352Z","iopub.status.idle":"2025-05-03T11:28:42.347632Z","shell.execute_reply.started":"2025-05-03T11:28:42.347492Z","shell.execute_reply":"2025-05-03T11:28:42.347504Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"ids = input_df.id.astype(str).tolist()\nseeker_posts = input_df.seeker_post.astype(str).tolist()\nresponse_posts = input_df.response_post.astype(str).tolist()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-03T11:28:42.348675Z","iopub.status.idle":"2025-05-03T11:28:42.348957Z","shell.execute_reply.started":"2025-05-03T11:28:42.348796Z","shell.execute_reply":"2025-05-03T11:28:42.348810Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"empathy_classifier = EmpathyClassifier(device,\n\t\t\t\t\t\tER_model_path = ER_model_path, \n\t\t\t\t\t\tIP_model_path = IP_model_path,\n\t\t\t\t\t\tEX_model_path = EX_model_path,)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-03T11:28:42.350020Z","iopub.status.idle":"2025-05-03T11:28:42.350244Z","shell.execute_reply.started":"2025-05-03T11:28:42.350148Z","shell.execute_reply":"2025-05-03T11:28:42.350157Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"output_file = codecs.open(output_path, 'w', 'utf-8')\ncsv_writer = csv.writer(output_file, delimiter=',', quotechar='\"')\ncsv_writer.writerow(['id','seeker_post','response_post','ER_label','IP_label','EX_label', 'ER_rationale', 'IP_rationale', 'EX_rationale'])","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-03T11:28:42.351976Z","iopub.status.idle":"2025-05-03T11:28:42.352294Z","shell.execute_reply.started":"2025-05-03T11:28:42.352137Z","shell.execute_reply":"2025-05-03T11:28:42.352151Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"for i in range(len(seeker_posts)):\n\t(logits_empathy_ER, predictions_ER, logits_empathy_IP, predictions_IP, logits_empathy_EX, predictions_EX, logits_rationale_ER, predictions_rationale_ER, logits_rationale_IP, predictions_rationale_IP, logits_rationale_EX,predictions_rationale_EX) = empathy_classifier.predict_empathy([seeker_posts[i]], [response_posts[i]])\n\n\tcsv_writer.writerow([ids[i], seeker_posts[i], response_posts[i], predictions_ER[0], predictions_IP[0], predictions_EX[0], predictions_rationale_ER[0].tolist(), predictions_rationale_IP[0].tolist(), predictions_rationale_EX[0].tolist()])","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-03T11:28:42.353015Z","iopub.status.idle":"2025-05-03T11:28:42.353302Z","shell.execute_reply.started":"2025-05-03T11:28:42.353154Z","shell.execute_reply":"2025-05-03T11:28:42.353168Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"output_file.close()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-03T11:28:42.354646Z","iopub.status.idle":"2025-05-03T11:28:42.354900Z","shell.execute_reply.started":"2025-05-03T11:28:42.354761Z","shell.execute_reply":"2025-05-03T11:28:42.354770Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"t = pd.read_csv(\"/kaggle/working/sample_test_input_out.csv\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-03T11:28:42.356491Z","iopub.status.idle":"2025-05-03T11:28:42.356755Z","shell.execute_reply.started":"2025-05-03T11:28:42.356645Z","shell.execute_reply":"2025-05-03T11:28:42.356654Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"input_df.loc[2291, 'response_post']","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-03T11:28:42.357504Z","iopub.status.idle":"2025-05-03T11:28:42.357786Z","shell.execute_reply.started":"2025-05-03T11:28:42.357646Z","shell.execute_reply":"2025-05-03T11:28:42.357658Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"t.head()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-03T11:28:42.358767Z","iopub.status.idle":"2025-05-03T11:28:42.358994Z","shell.execute_reply.started":"2025-05-03T11:28:42.358882Z","shell.execute_reply":"2025-05-03T11:28:42.358891Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}