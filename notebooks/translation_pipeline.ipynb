{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import re\n",
    "from dataclasses import dataclass, field\n",
    "from datetime import datetime\n",
    "from pathlib import Path\n",
    "\n",
    "import pandas as pd\n",
    "from datasets import Dataset\n",
    "from omegaconf import OmegaConf\n",
    "\n",
    "from src.core.translate import Translator\n",
    "from src.utils.schemas import (GeneralTranslationResultSchema,\n",
    "                               RationaleTranslationResultSchema)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [],
   "source": [
    "regex_check_enhlsih = re.compile(r'\\b[a-zA-Z]{2,}\\b')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [],
   "source": [
    "def contains_english(text: str) -> bool:\n",
    "\t\"\"\"\n",
    "\tChecks if the given text contains English words.\n",
    "\n",
    "\tArgs:\n",
    "\t\ttext (str): Text to check.\n",
    "\n",
    "\tReturns:\n",
    "\t\tbool:\t\tTrue if English words are found, False otherwise.\n",
    "\t\"\"\"\n",
    "\treturn bool(re.search(regex_check_enhlsih, text))\n",
    "\n",
    "def read_file(path: str):\n",
    "\treturn Path(path).open().read()\n",
    "\t\n",
    "def read_json(path: str):\n",
    "\treturn json.load(Path(path).open())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = OmegaConf.load('configs/conf.yaml')\n",
    "general_translation_config = config.general_translation\n",
    "general_translation_correction_config = config.general_translation_correction\n",
    "rationales_translation_config = config.rationales_translation\n",
    "rationales_translation_correction_config = config.rationales_translation_correction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [],
   "source": [
    "general_translator = Translator(\n",
    "    system_message=read_file(general_translation_config.prompt_path), \n",
    "    model_config=read_json(general_translation_config.model_config_path), \n",
    "    example_data=read_json(general_translation_config.filepath_examples), \n",
    "    batch_size=general_translation_config.batch_size,\n",
    "    batch_result_dir=general_translation_config.batch_result_dir,\n",
    "    batch_dir=general_translation_config.batches\n",
    ")\n",
    "\n",
    "general_translator_corrector = Translator(\n",
    "    system_message=read_file(general_translation_correction_config.prompt_path), \n",
    "    model_config=read_json(general_translation_correction_config.model_config_path), \n",
    "    example_data=read_json(general_translation_correction_config.filepath_examples), \n",
    "    batch_size=general_translation_correction_config.batch_size,\n",
    "    batch_result_dir=general_translation_correction_config.batch_result_dir,\n",
    "    batch_dir=general_translation_correction_config.batches\n",
    ")\n",
    "\n",
    "rational_translator = Translator(\n",
    "    system_message=read_file(rationales_translation_config.prompt_path), \n",
    "    model_config=read_json(rationales_translation_config.model_config_path), \n",
    "    example_data=read_json(rationales_translation_config.filepath_examples), \n",
    "    batch_size=rationales_translation_config.batch_size,\n",
    "    batch_result_dir=rationales_translation_config.batch_result_dir,\n",
    "    batch_dir=rationales_translation_config.batches\n",
    ")\n",
    "\n",
    "rational_translator_corrector = Translator(\n",
    "    system_message=read_file(rationales_translation_correction_config.prompt_path), \n",
    "    model_config=read_json(rationales_translation_correction_config.model_config_path), \n",
    "    example_data=read_json(rationales_translation_correction_config.filepath_examples), \n",
    "    batch_size=rationales_translation_correction_config.batch_size,\n",
    "    batch_result_dir=rationales_translation_correction_config.batch_result_dir,\n",
    "    batch_dir=rationales_translation_correction_config.batches\n",
    ")\n",
    "\n",
    "general_translation_int_path = f\"int_path_general_translator_{datetime.now()}.json\"\n",
    "rational_translation_int_path = f\"int_path_rational_translator_{datetime.now()}.json\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Translating"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_translations = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [],
   "source": [
    "general_data = json.load(Path(\"all_data.json\").open())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for name in [\"seeker_post\", \"response_post\"]:\n",
    "\tgeneral_dataset = [{\"id\": item['id'], \"text\": item[name]} for item in general_data]\n",
    "\tgeneral_input_dataset = Dataset.from_list(general_dataset)\n",
    "\tprint(general_input_dataset[0])\n",
    "\ttranslation_result = general_translator.translate(general_input_dataset, GeneralTranslationResultSchema)\n",
    "\ttexts_containing_english = Dataset.from_list(translation_result).filter(lambda text: contains_english(text['text_rus'])) \n",
    "\tprint(\"Texts containing English: \", texts_containing_english[\"text_rus\"])\n",
    "\tfor t in texts_containing_english:\n",
    "\t\ttranslation_result.remove(t)\n",
    "\tfor t in translation_result:\n",
    "\t\tflag = False\n",
    "\t\tfor item in all_translations:\n",
    "\t\t\tif t[\"id\"] == item['id']:\n",
    "\t\t\t\tflag = True\n",
    "\t\t\t\titem.update({f\"{name}_rus\": t[\"text_rus\"], f\"{name}_en\": t[\"text\"]})\n",
    "\t\t\t\tbreak\n",
    "\t\tif not flag:\n",
    "\t\t\tall_translations.append({\"id\": t[\"id\"], f\"{name}_rus\": t[\"text_rus\"], f\"{name}t_en\": t[\"text\"]})\n",
    "\tif texts_containing_english:\n",
    "\t\tjson.dump(texts_containing_english, Path(f\"wrong_translations_{name}\").open(\"w\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"posts_translations.json\", \"w\", encoding=\"utf-8\") as f:\n",
    "\tjson.dump(all_translations, f, ensure_ascii=False, indent=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Correcting translation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_dataset_correction = texts_containing_english.remove_columns([\"text\"]).rename_column(\"text_rus\", \"text\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "translation_result_corrected = general_translator_corrector.translate(input_dataset_correction, GeneralTranslationResultSchema)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "translation_result_corrected"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: [],\n",
       "    num_rows: 0\n",
       "})"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Dataset.from_list(translation_result_corrected).filter(lambda text: contains_english(text['text_rus'])) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "for item in translation_result_corrected:\n",
    "    if not contains_english(item['text_rus']):\n",
    "        translation_result.append(item)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(general_translation_int_path, \"w\", encoding=\"utf-8\") as f:\n",
    "\tjson.dump(translation_result, f, ensure_ascii=False, indent=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Translating rationales"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Filter: 100%|██████████| 15/15 [00:00<00:00, 723.52 examples/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'id': '7oi3es_ds9oti2', 'text_eng': \"Is that really so bad? Maybe it was the smart decision because you needed that time to read recover. You're being kind to yourself when you need it and that's important. Hope you feel better soon.\", 'text_rus': 'Действительно ли это так плохо? Возможно, это было умное решение, потому что вам нужно было это время, чтобы восстановиться. Вы добры к себе, когда это необходимо, и это важно. Надеюсь, вам скоро станет лучше.', 'rationales_eng': 'Hope you feel better soon|'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Creating json from Arrow format: 100%|██████████| 1/1 [00:00<00:00, 67.65ba/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing batch 1/1...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Creating json from Arrow format: 100%|██████████| 1/1 [00:00<00:00, 297.98ba/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Incorrectly translated:  []\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Filter: 100%|██████████| 15/15 [00:00<00:00, 4795.68 examples/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'id': '65m92s_dgbdk7z', 'text_eng': \"That's pretty vague, do you not know what you're doing in regards to a specific section of your life? Like school or work?\", 'text_rus': 'Это довольно расплывчато, ты не знаешь, что делаешь в отношении конкретной части своей жизни? Как школа или работа?', 'rationales_eng': \"do you not know what you're doing in regards to a specific section of your life? Like school or work?|\"}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Creating json from Arrow format: 100%|██████████| 1/1 [00:00<00:00, 1237.62ba/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing batch 1/1...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Creating json from Arrow format: 100%|██████████| 1/1 [00:00<00:00, 619.91ba/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Incorrectly translated:  []\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Filter: 100%|██████████| 15/15 [00:00<00:00, 4052.99 examples/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'id': '6b2cmc_dhj8tcb', 'text_eng': \"I think it's social anxiety , that creates paranoid feelings , unless I'm wrong but that's how I feel\", 'text_rus': 'Я думаю, это социальная тревожность, которая создаёт параноидальные чувства, если я не ошибаюсь, но вот так я себя чувствую', 'rationales_eng': \"unless I'm wrong but that's how I feel|\"}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Creating json from Arrow format: 100%|██████████| 1/1 [00:00<00:00, 1211.88ba/s]\n",
      "Creating json from Arrow format: 100%|██████████| 1/1 [00:00<00:00, 1315.65ba/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing batch 1/2...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Creating json from Arrow format: 100%|██████████| 1/1 [00:00<00:00, 131.63ba/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing batch 2/2...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Creating json from Arrow format: 100%|██████████| 1/1 [00:00<00:00, 203.54ba/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Incorrectly translated:  []\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "for name in [\"emotional_reactions_rationales\", \"explorations_rationales\", \"interpretations_rationales\"]:\n",
    "\tall_data = Dataset.from_list(general_data).filter(lambda x: x[name])\n",
    "\ttranslation_result_filtered = list(filter(lambda x: x['id'] in all_data['id'], all_translations))\n",
    "\tdataset_rationales = [{\"id\": item['id'], \"text_eng\": item[\"response_post\"], \"text_rus\": item1['response_post_rus'], 'rationales_eng': item[name]} for item, item1 in zip(all_data, translation_result_filtered)]\n",
    "\tinput_dataset_rationales = Dataset.from_list(dataset_rationales)\n",
    "\tprint(input_dataset_rationales[0])\n",
    "\ttranslation_result_rationales = rational_translator.translate(input_dataset_rationales, RationaleTranslationResultSchema)\n",
    "\tincorrectly_translated = [] \n",
    "\tfor item in translation_result_rationales:\n",
    "\t\trats = item['rationales_rus'].strip('|').split('|')\n",
    "\t\tif len(item['rationales_eng'].strip('|').split(\"|\")) != len(rats):\n",
    "\t\t\tincorrectly_translated.append(item)\n",
    "\t\tfor r in rats:\n",
    "\t\t\tif item['text_rus'].find(r) == -1:\n",
    "\t\t\t\tincorrectly_translated.append(item)\n",
    "\n",
    "\ttranslated_rationales = list(filter(lambda x : x not in incorrectly_translated, translation_result_rationales))\n",
    "\tprint(\"Incorrectly translated: \", incorrectly_translated)\n",
    "\tif incorrectly_translated:\n",
    "\t\tjson.dump(incorrectly_translated, Path(f\"wrong_translations_{name}\").open(\"w\"))\n",
    "\n",
    "\tfor t in translated_rationales:\n",
    "\t\tflag = False\n",
    "\t\tfor item in all_translations:\n",
    "\t\t\tif t[\"id\"] == item['id']:\n",
    "\t\t\t\tflag = True\n",
    "\t\t\t\titem.update({f\"{name}_rus\": t[\"rationales_rus\"], f\"{name}_en\": t[\"rationales_eng\"]})\n",
    "\t\t\t\tbreak"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [],
   "source": [
    "for a in general_data:\n",
    "    for item in all_translations:\n",
    "        if a[\"id\"] == item[\"id\"]:\n",
    "            item.update({\"emotional_reactions_level\": a[\"emotional_reactions_level\"], \"explorations_level\": a[\"explorations_level\"], \"interpretations_level\": a[\"interpretations_level\"]})\n",
    "            if a[\"emotional_reactions_level\"] == 0:\n",
    "                item.update({\"emotional_reactions_rationales_rus\": \"\", \"emotional_reactions_rationales_en\": \"\"})\n",
    "            if a[\"explorations_level\"] == 0:\n",
    "                item.update({\"explorations_rationales_rus\": \"\", \"explorations_rationales_en\": \"\"})\n",
    "            if a[\"interpretations_level\"] == 0:\n",
    "                item.update({\"interpretations_rationales_rus\": \"\", \"interpretations_rationales_en\": \"\"})\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"all_translations.json\", \"w\", encoding=\"utf-8\") as f:\n",
    "\tjson.dump(all_translations, f, ensure_ascii=False, indent=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Correcting rationales"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Filter: 100%|██████████| 30/30 [00:00<00:00, 11455.67 examples/s]\n"
     ]
    }
   ],
   "source": [
    "rationales_containing_english = Dataset.from_list(translation_result_rationales).filter(lambda text: contains_english(text['rationales_rus'])) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['id', 'text_rus', 'text_eng', 'rationales_eng', 'rationales_rus'],\n",
       "    num_rows: 0\n",
       "})"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rationales_containing_english"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "for t in rationales_containing_english:\n",
    "    translation_result_rationales.remove(t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "keys = ['id', 'text_rus', 'text_eng', 'rationales_rus']\n",
    "dataset_correction_rationales = {k: [d[k] for d in rationales_containing_english] for k in keys}\n",
    "dataset_correction_rationales['rationales_eng'] = dataset_correction_rationales.pop('rationales_rus')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_dataset_correction = Dataset.from_dict(dataset_correction_rationales)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "translation_result_corrected = rational_translator_corrector.translate(input_dataset_correction, RationaleTranslationResultSchema)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "translation_result_corrected"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: [],\n",
       "    num_rows: 0\n",
       "})"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Dataset.from_list(translation_result_corrected).filter(lambda text: contains_english(text['text_rus'])) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "for item, rationale in zip(translation_result_corrected, rationales_containing_english):\n",
    "    if not contains_english(item['text_rus']):\n",
    "        translation_result_rationales.append({'id': item['id'], 'rationales_eng': rationale['rationales_eng'], 'rationales_rus': item['text_rus'], 'text_rus': rationale['text_rus'], 'text_eng': rationale['text_eng']})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "d = Dataset.from_list(translation_result_rationales)\n",
    "with open(rational_translation_int_path, \"w\", encoding=\"utf-8\") as f:\n",
    "\tjson.dump(d.to_list(), f, ensure_ascii=False, indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "incorrectly_translated = [] \n",
    "for item in translation_result_rationales:\n",
    "    rats = item['rationales_rus'].split('|')\n",
    "    for r in rats:\n",
    "        if item['text_rus'].find(r) == -1:\n",
    "            incorrectly_translated.append(item)\n",
    "\n",
    "translated_rationales = list(filter(lambda x : x not in incorrectly_translated, translation_result_rationales))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d = Dataset.from_list(translation_result_rationales)\n",
    "with open(rational_translation_int_path, \"w\", encoding=\"utf-8\") as f:\n",
    "\tjson.dump(d.to_list(), f, ensure_ascii=False, indent=4)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
