{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.core.translate import Translator\n",
    "import pandas as pd\n",
    "from datasets import Dataset\n",
    "import configparser\n",
    "import json\n",
    "from pathlib import Path\n",
    "import re\n",
    "from datetime import datetime\n",
    "from src.utils.schemas import ResultSchema, ResultSchemaRationales"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = configparser.ConfigParser()\n",
    "config.read('configs/conf.yaml')\n",
    "cfg = config['DEFAULT']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "system_message = Path(cfg['prompt_path']).open().read()\n",
    "model_config = json.load(Path(cfg['model_config_path']).open())\n",
    "example_data = json.load(Path(cfg['filepath_examples']).open())\n",
    "\n",
    "intermediate_path = f'int_path_{model_config[\"model\"]}_{datetime.now()}.json'\n",
    "batch_size = int(cfg['batch_size'])\n",
    "batch_result_dir = cfg['batch_result_dir']\n",
    "batch_dir = cfg['batches']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Translating"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(cfg['data_path'])\n",
    "dataset = {colname: data[colname].tolist()\n",
    "\t\t\tfor colname in cfg['cols'].split()}\n",
    "input_dataset = Dataset.from_dict(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Creating json from Arrow format: 100%|██████████| 1/1 [00:00<00:00, 99.91ba/s]\n",
      "Creating json from Arrow format: 100%|██████████| 1/1 [00:00<00:00, 1101.16ba/s]\n",
      "Creating json from Arrow format: 100%|██████████| 1/1 [00:00<00:00, 975.65ba/s]\n",
      "Creating json from Arrow format: 100%|██████████| 1/1 [00:00<00:00, 1190.55ba/s]\n",
      "Creating json from Arrow format: 100%|██████████| 1/1 [00:00<00:00, 1082.40ba/s]\n",
      "Creating json from Arrow format: 100%|██████████| 1/1 [00:00<00:00, 1700.85ba/s]\n",
      "Creating json from Arrow format: 100%|██████████| 1/1 [00:00<00:00, 1285.41ba/s]\n",
      "Creating json from Arrow format: 100%|██████████| 1/1 [00:00<00:00, 745.12ba/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing batch 1/8...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:Error on input #3 (id: 3): Invalid control character at: line 4 column 231 (char 1209). Attempt 1 of 3. Retrying...\n",
      "Creating json from Arrow format: 100%|██████████| 1/1 [00:00<00:00, 200.92ba/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing batch 2/8...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Creating json from Arrow format: 100%|██████████| 1/1 [00:00<00:00, 476.84ba/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing batch 3/8...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Creating json from Arrow format: 100%|██████████| 1/1 [00:00<00:00, 471.75ba/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing batch 4/8...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Creating json from Arrow format: 100%|██████████| 1/1 [00:00<00:00, 661.88ba/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing batch 5/8...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Creating json from Arrow format: 100%|██████████| 1/1 [00:00<00:00, 670.66ba/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing batch 6/8...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Creating json from Arrow format: 100%|██████████| 1/1 [00:00<00:00, 565.57ba/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing batch 7/8...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:Error on input #0 (id: 24): Invalid control character at: line 4 column 76 (char 821). Attempt 1 of 3. Retrying...\n",
      "Creating json from Arrow format: 100%|██████████| 1/1 [00:00<00:00, 489.19ba/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing batch 8/8...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Creating json from Arrow format: 100%|██████████| 1/1 [00:00<00:00, 615.81ba/s]\n"
     ]
    }
   ],
   "source": [
    "tr = Translator(system_message, model_config, example_data, batch_size, batch_result_dir, batch_dir)\n",
    "translation_result = tr.translate(input_dataset, ResultSchema)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "regex_check_enhlsih = re.compile(r'\\b[a-zA-Z]{2,}\\b')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def contains_english(text: str) -> bool:\n",
    "\t\"\"\"\n",
    "\tChecks if the given text contains English words.\n",
    "\n",
    "\tArgs:\n",
    "\t\ttext (str): Text to check.\n",
    "\n",
    "\tReturns:\n",
    "\t\tbool:\t\tTrue if English words are found, False otherwise.\n",
    "\t\"\"\"\n",
    "\treturn bool(re.search(regex_check_enhlsih, text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "texts_containing_english = [text for text in translation_result if contains_english(text['text_rus'])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'id': '5',\n",
       "  'text': \"Thats totally normal, most people get that from time to time. It will pass, the when is the real question. Good news is you can work on the when, at least it works for me. I think the key is to accept whatever you are feeling, not fight it and not try to change it, even try to get yourself to cry. The point is really to change your mindset from 'i have depression i can't cure it, it is killing me' to 'i'm sad again for no reason, human brain is a pile of shit and buggy as hell, I'm gonny cry all day to give it what it wants'..\",\n",
       "  'text_rus': \"Это totally нормально, большинство людей испытывают это от случая к случаю. Это пройдёт, но ключевой вопрос — когда. Хорошая новость в том, что ты можешь работать над этим 'когда', по крайней мере, это работает на мне. Я думаю, что ключ в том, чтобы принять то, что ты чувствуешь, не сопротивляться этому и не пытаться изменить это, даже попытаться дать себе возможность поплакать. Точка в том, чтобы изменить свое отношение с 'у меня депрессия, я не могу её вылечить, она убивает меня' на 'опять грустно без причины, человеческий мозг — куча дерьма и битый, я буду плакать весь день, чтобы дать ему, что он хочет'..\"},\n",
       " {'id': '21',\n",
       "  'text': \"Same, well obviosuly I don't know how you feel 100% but I thinks its appropiate to say I can relate to you deeply. Why don't we try distract ourselves, even if its just 5 mins. Listen to a song you like, watch a small video, browse r/eyebleach or even go drink water. Im gonna try and watch something in youtube to at least try and not think about you know what. Wannna try with me? :)\",\n",
       "  'text_rus': 'То же самое, claro, я, конечно, не знаю, как вы себя чувствуете на 100%, но думаю, что можно сказать, что я очень вас понимаю. Почему бы нам не попробовать отвлечься, даже если это только на 5 минут? Послушай песню, которую тебе нравится, посмотри короткое видео, покрутиься на r/eyebleach или даже просто пей воду. Я попробую посмотреть что-нибудь на YouTube, чтобы заставить себя не думать об этом. Хочешь попробовать вместе со мной? :)'},\n",
       " {'id': '26',\n",
       "  'text': \"As someone who's felt the same, what do you have? And I'm speaking objectively, because I typically don't want to admit that I have what I need when I feel as you do. Not that I'm saying that you do have a lot, but your post doesn't necessarily shed a lot of light on what's going on. It's easy, or it has been for me, at least, to say that I don't know what to live for, in the past. Somebody out there cares, man/woman, small or large. I don't know what your situation is, by your post, but feel free to message me if you want.\",\n",
       "  'text_rus': 'Как человек, который испытывал то же, что у тебя. Что у тебя есть? И я говорю объективно, потому что обычно я не хочу признавать, что у меня есть то, что мне нужно, когда я чувствую себя так же, как и ты. Не то чтобы я говорю, что у тебя много чего, но твой пост не обязательно многое проясняет. Легко, или по крайней мере, это было для меня, сказать, что я не знаю, за что мне жить в прошлом. Кто-то там заботится о тебе, мужчина/женщина, маленький или большой. Я не знаю, с чем ты столкнулся, по твоему посту, но не стесняйся sendMessage мне, если захочешь.'}]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "texts_containing_english"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "for t in texts_containing_english:\n",
    "    translation_result.remove(t)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Correcting translation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = configparser.ConfigParser()\n",
    "config.read('configs/conf_correction.yaml')\n",
    "cfg = config['DEFAULT']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "system_message = Path(cfg['prompt_path']).open().read()\n",
    "model_config = json.load(Path(cfg['model_config_path']).open())\n",
    "example_data = json.load(Path(cfg['filepath_examples']).open())\n",
    "\n",
    "batch_size = int(cfg['batch_size'])\n",
    "batch_result_dir = cfg['batch_result_dir']\n",
    "batch_dir = cfg['batches']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_correction = {'id': [], 'text': []}\n",
    "for item in texts_containing_english:\n",
    "    dataset_correction['id'].append(item['id'])\n",
    "    dataset_correction['text'].append(item['text_rus'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_dataset_correction = Dataset.from_dict(dataset_correction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Creating json from Arrow format: 100%|██████████| 1/1 [00:00<00:00, 661.04ba/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing batch 1/1...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Creating json from Arrow format: 100%|██████████| 1/1 [00:00<00:00, 331.25ba/s]\n"
     ]
    }
   ],
   "source": [
    "tr = Translator(system_message, model_config, example_data, batch_size, batch_result_dir, batch_dir)\n",
    "translation_result_corrected = tr.translate(input_dataset_correction, ResultSchema)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'id': '5',\n",
       "  'text': \"Это totally нормально, большинство людей испытывают это от случая к случаю. Это пройдёт, но ключевой вопрос — когда. Хорошая новость в том, что ты можешь работать над этим 'когда', по крайней мере, это работает на мне. Я думаю, что ключ в том, чтобы принять то, что ты чувствуешь, не сопротивляться этому и не пытаться изменить это, даже попытаться дать себе возможность поплакать. Точка в том, чтобы изменить свое отношение с 'у меня депрессия, я не могу её вылечить, она убивает меня' на 'опять грустно без причины, человеческий мозг — куча дерьма и битый, я буду плакать весь день, чтобы дать ему, что он хочет'.\",\n",
       "  'text_rus': \"Это полностью нормально, большинство людей испытывают это от случая к случаю. Это пройдёт, но ключевой вопрос — когда. Хорошая новость в том, что ты можешь работать над этим 'когда', по крайней мере, это работает на мне. Я думаю, что ключ в том, чтобы принять то, что ты чувствуешь, не сопротивляться этому и не пытаться изменить это, даже попытаться дать себе возможность поплакать. Точка в том, чтобы изменить свое отношение с 'у меня депрессия, я не могу её вылечить, она убивает меня' на 'опять грустно без причины, человеческий мозг — куча дерьма и битый, я буду плакать весь день, чтобы дать ему, что он хочет'.\"},\n",
       " {'id': '21',\n",
       "  'text': 'То же самое, claro, я, конечно, не знаю, как вы себя чувствуете на 100%, но думаю, что можно сказать, что я очень вас понимаю. Почему бы нам не попробовать отвлечься, даже если это только на 5 минут? Послушай песню, которую тебе нравится, посмотри короткое видео, покрутиься на r/eyebleach или даже просто пей воду. Я попробую посмотреть что-нибудь на YouTube, чтобы заставить себя не думать об этом. Хочешь попробовать вместе со мной? :)',\n",
       "  'text_rus': 'То же самое, конечно, я, конечно, не знаю, как вы себя чувствуете на 100%, но думаю, что можно сказать, что я очень вас понимаю. Почему бы нам не попробовать отвлечься, даже если это только на 5 минут? Послушай песню, которую тебе нравится, посмотри короткое видео, покрутиься на форуме с странными изображениями или даже просто пей воду. Я попробую посмотреть что-нибудь на видеохостинге, чтобы заставить себя не думать об этом. Хочешь попробовать вместе со мной? :)'},\n",
       " {'id': '26',\n",
       "  'text': 'Как человек, который испытывал то же, что у тебя. Что у тебя есть? И я говорю объективно, потому что обычно я не хочу признавать, что у меня есть то, что мне нужно, когда я чувствую себя так же, как и ты. Не то чтобы я говорю, что у тебя много чего, но твой пост не обязательно многое проясняет. Легко, или по крайней мере, это было для меня, сказать, что я не знаю, за что мне жить в прошлом. Кто-то там заботится о тебе, мужчина/женщина, маленький или большой. Я не знаю, с чем ты столкнулся, по твоему посту, но не стесняйся sendMessage мне, если захочешь.',\n",
       "  'text_rus': 'Как человек, который испытывал то же, что у тебя. Что у тебя есть? И я говорю объективно, потому что обычно я не хочу признавать, что у меня есть то, что мне нужно, когда я чувствую себя так же, как и ты. Не то чтобы я говорю, что у тебя много чего, но твой пост не обязательно многое проясняет. Легко, или по крайней мере, это было для меня, сказать, что я не знаю, за что мне жить в прошлом. Кто-то там заботится о тебе, мужчина женщина, маленький или большой. Я не знаю, с чем ты столкнулся, по твоему посту, но не стесняйся напиши мне, если захочешь.'}]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "translation_result_corrected"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[False, False, False]\n"
     ]
    }
   ],
   "source": [
    "print([contains_english(t['text_rus']) for t in translation_result_corrected])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "for item in translation_result_corrected:\n",
    "    if not contains_english(item['text_rus']):\n",
    "        translation_result.append(item)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "if intermediate_path:\n",
    "\td = Dataset.from_list(translation_result)\n",
    "\twith open(intermediate_path, \"w\", encoding=\"utf-8\") as f:\n",
    "\t\tjson.dump(d.to_list(), f, ensure_ascii=False, indent=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Translating rationales"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = configparser.ConfigParser()\n",
    "config.read('configs/conf_rationales.yaml')\n",
    "cfg = config['DEFAULT']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "system_message = Path(cfg['prompt_path']).open().read()\n",
    "model_config = json.load(Path(cfg['model_config_path']).open())\n",
    "example_data = json.load(Path(cfg['filepath_examples']).open())\n",
    "intermediate_path = f\"data/int_path_{model_config['model']}_{datetime.now()}-rationales.json\"\n",
    "\n",
    "batch_size = int(cfg['batch_size'])\n",
    "batch_result_dir = cfg['batch_result_dir']\n",
    "batch_dir = cfg['batches']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(cfg['data_path']) as f:\n",
    "    dataset_rationales = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_rationales['id'] = [i for i in range(len(dataset_rationales['text_eng']))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_dataset_rationales = Dataset.from_dict(dataset_rationales)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Creating json from Arrow format: 100%|██████████| 1/1 [00:00<00:00, 52.06ba/s]\n",
      "Creating json from Arrow format: 100%|██████████| 1/1 [00:00<00:00, 852.50ba/s]\n",
      "Creating json from Arrow format: 100%|██████████| 1/1 [00:00<00:00, 1178.18ba/s]\n",
      "Creating json from Arrow format: 100%|██████████| 1/1 [00:00<00:00, 1109.60ba/s]\n",
      "Creating json from Arrow format: 100%|██████████| 1/1 [00:00<00:00, 1200.43ba/s]\n",
      "Creating json from Arrow format: 100%|██████████| 1/1 [00:00<00:00, 932.90ba/s]\n",
      "Creating json from Arrow format: 100%|██████████| 1/1 [00:00<00:00, 1043.88ba/s]\n",
      "Creating json from Arrow format: 100%|██████████| 1/1 [00:00<00:00, 1097.99ba/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing batch 1/8...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Creating json from Arrow format: 100%|██████████| 1/1 [00:00<00:00, 54.12ba/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing batch 2/8...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Creating json from Arrow format: 100%|██████████| 1/1 [00:00<00:00, 373.29ba/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing batch 3/8...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Creating json from Arrow format: 100%|██████████| 1/1 [00:00<00:00, 330.78ba/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing batch 4/8...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Creating json from Arrow format: 100%|██████████| 1/1 [00:00<00:00, 666.71ba/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing batch 5/8...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Creating json from Arrow format: 100%|██████████| 1/1 [00:00<00:00, 634.54ba/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing batch 6/8...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Creating json from Arrow format: 100%|██████████| 1/1 [00:00<00:00, 506.86ba/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing batch 7/8...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Creating json from Arrow format: 100%|██████████| 1/1 [00:00<00:00, 604.98ba/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing batch 8/8...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Creating json from Arrow format: 100%|██████████| 1/1 [00:00<00:00, 512.31ba/s]\n"
     ]
    }
   ],
   "source": [
    "tr = Translator(system_message, model_config, example_data, batch_size, batch_result_dir, batch_dir)\n",
    "translation_result_rationales = tr.translate(input_dataset_rationales, ResultSchemaRationales)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Correcting rationales"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "texts_containing_english = [text for text in translation_result_rationales if contains_english(text['rationales_rus'])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'id': '0',\n",
       "  'text_rus': 'Это действительно так плохо? Возможно, это было умным решением, потому что вам было нужно это время, чтобы восстановиться. Вы проявляете к себе доброту, когда это необходимо, и это важно. Надеюсь, вы скоро почувствуете себя лучше.',\n",
       "  'text_eng': \"Is that really so bad? Maybe it was the smart decision because you needed that time to read recover. You're being kind to yourself when you need it and that's important. Hope you feel better soon.\",\n",
       "  'rationales_eng': 'Hope you feel better soon|',\n",
       "  'rationales_rus': 'Hope you скоро почувствуете себя лучше.'}]"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "texts_containing_english"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for t in texts_containing_english:\n",
    "    translation_result_rationales.remove(t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = configparser.ConfigParser()\n",
    "config.read('configs/conf_correction.yaml')\n",
    "cfg = config['DEFAULT']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "system_message = Path(cfg['prompt_path']).open().read()\n",
    "model_config = json.load(Path(cfg['model_config_path']).open())\n",
    "example_data = json.load(Path(cfg['filepath_examples']).open())\n",
    "\n",
    "batch_size = int(cfg['batch_size'])\n",
    "batch_result_dir = cfg['batch_result_dir']\n",
    "batch_dir = cfg['batches']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_correction = {'id': [], 'text_rus': [], 'text_eng': [], 'rationales_eng': []}\n",
    "for item in texts_containing_english:\n",
    "    dataset_correction['id'].append(item['id'])\n",
    "    dataset_correction['text_rus'].append(item['text_rus'])\n",
    "    dataset_correction['text_eng'].append(item['text_eng'])\n",
    "    dataset_correction['rationales_eng'].append(item['rationales_rus'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_dataset_correction = Dataset.from_dict(dataset_correction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Creating json from Arrow format: 100%|██████████| 1/1 [00:00<00:00, 217.50ba/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing batch 1/1...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Creating json from Arrow format: 100%|██████████| 1/1 [00:00<00:00, 356.78ba/s]\n"
     ]
    }
   ],
   "source": [
    "tr = Translator(system_message, model_config, example_data, batch_size, batch_result_dir, batch_dir)\n",
    "translation_result_corrected = tr.translate(input_dataset_correction, ResultSchemaRationales)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'id': '0',\n",
       "  'text_rus': 'Это действительно так плохо? Возможно, это было умным решением, потому что вам было нужно это время, чтобы восстановиться. Вы проявляете к себе доброту, когда это необходимо, и это важно. Надеюсь, вы скоро почувствуете себя лучше.',\n",
       "  'text_eng': \"Is that really so bad? Maybe it was the smart decision because you needed that time to read recover. You're being kind to yourself when you need it and that's important. Hope you feel better soon.\",\n",
       "  'rationales_eng': 'Hope you скоро почувствуете себя лучше.',\n",
       "  'rationales_rus': 'Надеюсь, вы скоро почувствуете себя лучше.'}]"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "translation_result_corrected"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[False]\n"
     ]
    }
   ],
   "source": [
    "print([contains_english(t['text_rus']) for t in translation_result_corrected])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "for item, rationale in zip(translation_result_corrected, texts_containing_english):\n",
    "    if not contains_english(item['text_rus']):\n",
    "        translation_result_rationales.append({'id': item['id'], 'rationales_eng': rationale['rationales_eng'], 'rationales_rus': item['text_rus'], 'text_rus': rationale['text_rus'], 'text_eng': rationale['text_eng']})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "if intermediate_path:\n",
    "\td = Dataset.from_list(translation_result_rationales)\n",
    "\twith open(intermediate_path, \"w\", encoding=\"utf-8\") as f:\n",
    "\t\tjson.dump(d.to_list(), f, ensure_ascii=False, indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sentence_transformers import SentenceTransformer\n",
    "import numpy as np\n",
    "\n",
    "model = SentenceTransformer('sentence-transformers/LaBSE')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "L1-норма (разница между векторами): 11.428401947021484\n",
      "L1-норма (разница между векторами): 12.030906677246094\n",
      "L1-норма (разница между векторами): 9.96324348449707\n",
      "L1-норма (разница между векторами): 9.975038528442383\n",
      "L1-норма (разница между векторами): 10.744906425476074\n",
      "L1-норма (разница между векторами): 10.01419448852539\n",
      "L1-норма (разница между векторами): 11.401578903198242\n",
      "L1-норма (разница между векторами): 10.81946849822998\n",
      "L1-норма (разница между векторами): 11.075176239013672\n",
      "L1-норма (разница между векторами): 13.749931335449219\n",
      "L1-норма (разница между векторами): 9.930123329162598\n",
      "L1-норма (разница между векторами): 15.17106819152832\n",
      "L1-норма (разница между векторами): 8.267402648925781\n",
      "L1-норма (разница между векторами): 8.864448547363281\n",
      "L1-норма (разница между векторами): 11.623388290405273\n",
      "L1-норма (разница между векторами): 13.545312881469727\n",
      "L1-норма (разница между векторами): 11.646284103393555\n",
      "L1-норма (разница между векторами): 6.259558200836182\n",
      "L1-норма (разница между векторами): 10.157197952270508\n",
      "L1-норма (разница между векторами): 9.352128028869629\n",
      "L1-норма (разница между векторами): 8.799224853515625\n",
      "L1-норма (разница между векторами): 13.82656192779541\n",
      "L1-норма (разница между векторами): 9.37213134765625\n",
      "L1-норма (разница между векторами): 8.715020179748535\n",
      "L1-норма (разница между векторами): 10.89771556854248\n",
      "L1-норма (разница между векторами): 10.558723449707031\n",
      "L1-норма (разница между векторами): 14.560540199279785\n",
      "L1-норма (разница между векторами): 0.6065929532051086\n",
      "L1-норма (разница между векторами): 5.6416015625\n",
      "L1-норма (разница между векторами): 3.2216835021972656\n"
     ]
    }
   ],
   "source": [
    "for item in translation_result:\n",
    "\tembedding_rus = model.encode(item['text_rus'])\n",
    "\tembedding_eng = model.encode(item['text'])\n",
    "\n",
    "\tl1_diff = np.sum(np.abs(embedding_rus - embedding_eng))\n",
    "\n",
    "\tprint(f\"L1-норма (разница между векторами): {l1_diff}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
