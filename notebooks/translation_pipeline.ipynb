{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import re\n",
    "from dataclasses import dataclass, field\n",
    "from datetime import datetime\n",
    "from pathlib import Path\n",
    "\n",
    "import pandas as pd\n",
    "from datasets import Dataset\n",
    "from omegaconf import OmegaConf\n",
    "\n",
    "from src.core.translate import Translator\n",
    "from src.utils.schemas import (GeneralTranslationResultSchema,\n",
    "                               RationaleTranslationResultSchema)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "regex_check_enhlsih = re.compile(r'\\b[a-zA-Z]{2,}\\b')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def contains_english(text: str) -> bool:\n",
    "\t\"\"\"\n",
    "\tChecks if the given text contains English words.\n",
    "\n",
    "\tArgs:\n",
    "\t\ttext (str): Text to check.\n",
    "\n",
    "\tReturns:\n",
    "\t\tbool:\t\tTrue if English words are found, False otherwise.\n",
    "\t\"\"\"\n",
    "\treturn bool(re.search(regex_check_enhlsih, text))\n",
    "\n",
    "def read_file(path: str):\n",
    "\treturn Path(path).open().read()\n",
    "\t\n",
    "def read_json(path: str):\n",
    "\treturn json.load(Path(path).open())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = OmegaConf.load('configs/conf.yaml')\n",
    "general_translation_config = config.general_translation\n",
    "general_translation_correction_config = config.general_translation_correction\n",
    "rationales_translation_config = config.rationales_translation\n",
    "rationales_translation_correction_config = config.rationales_translation_correction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "general_translator = Translator(\n",
    "    system_message=read_file(general_translation_config.prompt_path), \n",
    "    model_config=read_json(general_translation_config.model_config_path), \n",
    "    example_data=read_json(general_translation_config.filepath_examples), \n",
    "    batch_size=general_translation_config.batch_size,\n",
    "    batch_result_dir=general_translation_config.batch_result_dir,\n",
    "    batch_dir=general_translation_config.batches\n",
    ")\n",
    "\n",
    "general_translator_corrector = Translator(\n",
    "    system_message=read_file(general_translation_correction_config.prompt_path), \n",
    "    model_config=read_json(general_translation_correction_config.model_config_path), \n",
    "    example_data=read_json(general_translation_correction_config.filepath_examples), \n",
    "    batch_size=general_translation_correction_config.batch_size,\n",
    "    batch_result_dir=general_translation_correction_config.batch_result_dir,\n",
    "    batch_dir=general_translation_correction_config.batches\n",
    ")\n",
    "\n",
    "rational_translator = Translator(\n",
    "    system_message=read_file(rationales_translation_config.prompt_path), \n",
    "    model_config=read_json(rationales_translation_config.model_config_path), \n",
    "    example_data=read_json(rationales_translation_config.filepath_examples), \n",
    "    batch_size=rationales_translation_config.batch_size,\n",
    "    batch_result_dir=rationales_translation_config.batch_result_dir,\n",
    "    batch_dir=rationales_translation_config.batches\n",
    ")\n",
    "\n",
    "rational_translator_corrector = Translator(\n",
    "    system_message=read_file(rationales_translation_correction_config.prompt_path), \n",
    "    model_config=read_json(rationales_translation_correction_config.model_config_path), \n",
    "    example_data=read_json(rationales_translation_correction_config.filepath_examples), \n",
    "    batch_size=rationales_translation_correction_config.batch_size,\n",
    "    batch_result_dir=rationales_translation_correction_config.batch_result_dir,\n",
    "    batch_dir=rationales_translation_correction_config.batches\n",
    ")\n",
    "\n",
    "general_translation_int_path = f\"int_path_general_translator\"\n",
    "rational_translation_int_path = f\"int_path_rational_translator\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Translating"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "general_data = pd.read_csv(general_translation_config.data_path)\n",
    "general_dataset = {colname: general_data[colname].tolist() for colname in general_translation_config.cols.split()}\n",
    "general_input_dataset = Dataset.from_dict(general_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Creating json from Arrow format: 100%|██████████| 1/1 [00:00<00:00, 288.35ba/s]\n",
      "Creating json from Arrow format: 100%|██████████| 1/1 [00:00<00:00, 1376.08ba/s]\n",
      "Creating json from Arrow format: 100%|██████████| 1/1 [00:00<00:00, 1494.76ba/s]\n",
      "Creating json from Arrow format: 100%|██████████| 1/1 [00:00<00:00, 1298.55ba/s]\n",
      "Creating json from Arrow format: 100%|██████████| 1/1 [00:00<00:00, 1592.37ba/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing batch 1/5...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Creating json from Arrow format: 100%|██████████| 1/1 [00:00<00:00, 1323.96ba/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing batch 2/5...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Creating json from Arrow format: 100%|██████████| 1/1 [00:00<00:00, 400.33ba/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing batch 3/5...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Creating json from Arrow format: 100%|██████████| 1/1 [00:00<00:00, 841.22ba/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing batch 4/5...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Creating json from Arrow format: 100%|██████████| 1/1 [00:00<00:00, 426.60ba/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing batch 5/5...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Creating json from Arrow format: 100%|██████████| 1/1 [00:00<00:00, 590.33ba/s]\n"
     ]
    }
   ],
   "source": [
    "translation_result = general_translator.translate(general_input_dataset, GeneralTranslationResultSchema)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Filter: 100%|██████████| 19/19 [00:00<00:00, 2248.26 examples/s]\n"
     ]
    }
   ],
   "source": [
    "texts_containing_english = Dataset.from_list(translation_result).filter(lambda text: contains_english(text['text_rus'])) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "texts_containing_english[\"text_rus\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "for t in texts_containing_english:\n",
    "    translation_result.remove(t)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Correcting translation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_dataset_correction = texts_containing_english.remove_columns([\"text\"]).rename_column(\"text_rus\", \"text\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "translation_result_corrected = general_translator_corrector.translate(input_dataset_correction, GeneralTranslationResultSchema)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "translation_result_corrected"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: [],\n",
       "    num_rows: 0\n",
       "})"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Dataset.from_list(translation_result_corrected).filter(lambda text: contains_english(text['text_rus'])) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "for item in translation_result_corrected:\n",
    "    if not contains_english(item['text_rus']):\n",
    "        translation_result.append(item)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(general_translation_int_path, \"w\", encoding=\"utf-8\") as f:\n",
    "\tjson.dump(translation_result, f, ensure_ascii=False, indent=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Translating rationales"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_rationales = json.load(Path(rationales_translation_config.data_path).open())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_dataset_rationales = Dataset.from_dict(dataset_rationales)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Creating json from Arrow format: 100%|██████████| 1/1 [00:00<00:00, 290.26ba/s]\n",
      "Creating json from Arrow format: 100%|██████████| 1/1 [00:00<00:00, 1414.61ba/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Creating json from Arrow format: 100%|██████████| 1/1 [00:00<00:00, 107.31ba/s]\n",
      "Creating json from Arrow format: 100%|██████████| 1/1 [00:00<00:00, 337.05ba/s]\n",
      "Creating json from Arrow format: 100%|██████████| 1/1 [00:00<00:00, 1296.94ba/s]\n",
      "Creating json from Arrow format: 100%|██████████| 1/1 [00:00<00:00, 1478.95ba/s]\n",
      "Creating json from Arrow format: 100%|██████████| 1/1 [00:00<00:00, 768.05ba/s]\n",
      "Creating json from Arrow format: 100%|██████████| 1/1 [00:00<00:00, 1494.76ba/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing batch 1/8...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Creating json from Arrow format: 100%|██████████| 1/1 [00:00<00:00, 303.85ba/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing batch 2/8...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Creating json from Arrow format: 100%|██████████| 1/1 [00:00<00:00, 217.82ba/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing batch 3/8...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Creating json from Arrow format: 100%|██████████| 1/1 [00:00<00:00, 280.59ba/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing batch 4/8...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Creating json from Arrow format: 100%|██████████| 1/1 [00:00<00:00, 205.08ba/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing batch 5/8...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR:root:Unexpected error on input #3 (id: 19): 'id'. Attempt 1 of 3. Retrying...\n",
      "Creating json from Arrow format: 100%|██████████| 1/1 [00:00<00:00, 943.60ba/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing batch 6/8...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Creating json from Arrow format: 100%|██████████| 1/1 [00:00<00:00, 579.72ba/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing batch 7/8...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Creating json from Arrow format: 100%|██████████| 1/1 [00:00<00:00, 648.87ba/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing batch 8/8...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Creating json from Arrow format: 100%|██████████| 1/1 [00:00<00:00, 313.48ba/s]\n"
     ]
    }
   ],
   "source": [
    "translation_result_rationales = rational_translator.translate(input_dataset_rationales, RationaleTranslationResultSchema)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "incorrectly_translated = [] \n",
    "for item in translation_result_rationales:\n",
    "    rats = item['rationales_rus'].split('|')\n",
    "    for r in rats:\n",
    "        if item['text_rus'].find(r) == -1:\n",
    "            incorrectly_translated.append(item)\n",
    "\n",
    "translated_rationales = list(filter(lambda x : x not in incorrectly_translated, translation_result_rationales))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "incorrectly_translated"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Correcting rationales"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Filter: 100%|██████████| 30/30 [00:00<00:00, 11455.67 examples/s]\n"
     ]
    }
   ],
   "source": [
    "rationales_containing_english = Dataset.from_list(translation_result_rationales).filter(lambda text: contains_english(text['rationales_rus'])) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['id', 'text_rus', 'text_eng', 'rationales_eng', 'rationales_rus'],\n",
       "    num_rows: 0\n",
       "})"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rationales_containing_english"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "for t in rationales_containing_english:\n",
    "    translation_result_rationales.remove(t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "keys = ['id', 'text_rus', 'text_eng', 'rationales_rus']\n",
    "dataset_correction_rationales = {k: [d[k] for d in rationales_containing_english] for k in keys}\n",
    "dataset_correction_rationales['rationales_eng'] = dataset_correction_rationales.pop('rationales_rus')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_dataset_correction = Dataset.from_dict(dataset_correction_rationales)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "translation_result_corrected = rational_translator_corrector.translate(input_dataset_correction, RationaleTranslationResultSchema)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "translation_result_corrected"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: [],\n",
       "    num_rows: 0\n",
       "})"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Dataset.from_list(translation_result_corrected).filter(lambda text: contains_english(text['text_rus'])) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "for item, rationale in zip(translation_result_corrected, rationales_containing_english):\n",
    "    if not contains_english(item['text_rus']):\n",
    "        translation_result_rationales.append({'id': item['id'], 'rationales_eng': rationale['rationales_eng'], 'rationales_rus': item['text_rus'], 'text_rus': rationale['text_rus'], 'text_eng': rationale['text_eng']})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "d = Dataset.from_list(translation_result_rationales)\n",
    "with open(rational_translation_int_path, \"w\", encoding=\"utf-8\") as f:\n",
    "\tjson.dump(d.to_list(), f, ensure_ascii=False, indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "incorrectly_translated = [] \n",
    "for item in translation_result_rationales:\n",
    "    rats = item['rationales_rus'].split('|')\n",
    "    for r in rats:\n",
    "        if item['text_rus'].find(r) == -1:\n",
    "            incorrectly_translated.append(item)\n",
    "\n",
    "translated_rationales = list(filter(lambda x : x not in incorrectly_translated, translation_result_rationales))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
